{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb8079c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 19:12:31.475217: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-02 19:12:31.479599: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-02 19:12:31.518449: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-02 19:12:31.554664: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-02 19:12:31.598955: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-02 19:12:31.608518: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-02 19:12:31.662892: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-02 19:12:32.299468: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/diego2/fem/Accelerated_Contact_Detection\n",
      "Total data size (1% sample): 800000\n",
      "Training set size: 640000\n",
      "Test set size: 160000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from pdb import set_trace\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "# Directory to save logs for TensorBoard\n",
    "log_dir = \"logs/fit/\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "# Define the path where your CSV files are located\n",
    "csv_files_path = '../csv_files/*.csv'\n",
    "\n",
    "# Uncomment this section if you need to recreate a random 1% sample\n",
    "data_frames = []\n",
    "for file in glob.glob(csv_files_path):\n",
    "    df = pd.read_csv(file, header=None)  # Load without headers\n",
    "    if df.shape[1] == 7:                 # Ensure it has exactly 7 columns\n",
    "        data_frames.append(df)           # Append if structure is correct\n",
    "    else:\n",
    "        print(f\"Skipping file {file} due to unexpected number of columns: {df.shape[1]}\")\n",
    "\n",
    "# Concatenate all valid DataFrames\n",
    "all_data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Assign column names\n",
    "all_data.columns = ['x', 'y', 'z', 'p_id', 'xi1', 'xi2', 'gn']\n",
    "\n",
    "# Drop any rows with NaN values\n",
    "all_data.dropna(inplace=True)\n",
    "\n",
    "# Randomly sample 1% of the data\n",
    "sampled_data = all_data.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Save the sample\n",
    "sampled_data.to_csv('sampled_data_10_percent.csv', index=False)\n",
    "\n",
    "# Load the pre-saved 1% sampled data\n",
    "sampled_data = pd.read_csv('sampled_data_10_percent.csv')\n",
    "\n",
    "# Split into features (x, y, z) and labels (p_id, xi1, xi2, gn)\n",
    "features = sampled_data[['x', 'y', 'z']].values\n",
    "labels = sampled_data[['p_id', 'xi1', 'xi2', 'gn']].values\n",
    "\n",
    "# Convert to TensorFlow dataset with (features, labels) tuples\n",
    "sampled_data = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "# Define the split ratio (80% train, 20% test)\n",
    "train_size = int(0.8 * len(sampled_data))\n",
    "train_data = sampled_data.take(train_size)\n",
    "test_data = sampled_data.skip(train_size)\n",
    "\n",
    "# Print dataset sizes to confirm\n",
    "print(f\"Total data size (1% sample): {len(sampled_data)}\")\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f895c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Adjust labels to match the output structure of the model (4 values per patch * 96 patches)\n",
    "labels_expanded = np.zeros((len(labels), 4 * 96))\n",
    "\n",
    "# Populate the expanded labels array for each sample\n",
    "for idx, (p_id, xi1, xi2, gn) in enumerate(labels):\n",
    "    # Assuming p_id is the patch index (0 to 95)\n",
    "    patch_idx = int(p_id)\n",
    "    labels_expanded[idx, patch_idx] = 1  # One-hot encoding for p_id\n",
    "    labels_expanded[idx, 96 + patch_idx] = xi1\n",
    "    labels_expanded[idx, 192 + patch_idx] = xi2\n",
    "    labels_expanded[idx, 288 + patch_idx] = gn\n",
    "\n",
    "# Update the TensorFlow dataset with expanded labels\n",
    "sampled_data = tf.data.Dataset.from_tensor_slices((features, labels_expanded))\n",
    "\n",
    "# Define the split ratio (80% train, 20% test)\n",
    "train_size = int(0.8 * len(sampled_data))\n",
    "train_data = sampled_data.take(train_size)\n",
    "test_data = sampled_data.skip(train_size)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "\n",
    "    # Classification loss for the first 96 outputs (p_id prediction)\n",
    "    p_id_true = y_true[:, :96]  # True one-hot encoded patch IDs\n",
    "    p_id_pred = y_pred[:, :96]  # Predicted patch probabilities\n",
    "\n",
    "    # Use categorical cross-entropy for patch classification\n",
    "    classification_loss = tf.reduce_mean(\n",
    "        tf.keras.losses.categorical_crossentropy(p_id_true, p_id_pred, from_logits=True)\n",
    "    )\n",
    "\n",
    "    # Regression targets for xi1, xi2, and gn\n",
    "    xi1_true = y_true[:, 96:192]\n",
    "    xi1_pred = y_pred[:, 96:192]\n",
    "    xi2_true = y_true[:, 192:288]\n",
    "    xi2_pred = y_pred[:, 192:288]\n",
    "    gn_true = y_true[:, 288:]\n",
    "    gn_pred = y_pred[:, 288:]\n",
    "\n",
    "    # Weighted sum product using p_id_true as a mask to select the target patch\n",
    "    xi1_loss = tf.reduce_sum(p_id_true * tf.square(xi1_true - xi1_pred), axis=1)\n",
    "    xi2_loss = tf.reduce_sum(p_id_true * tf.square(xi2_true - xi2_pred), axis=1)\n",
    "    gn_loss = tf.reduce_sum(p_id_true * tf.square(gn_true - gn_pred), axis=1)\n",
    "\n",
    "    # Average regression loss over the batch\n",
    "    regression_loss = tf.reduce_mean(xi1_loss + xi2_loss + gn_loss)\n",
    "    # Total loss: Combine classification and regression losses\n",
    "    total_loss = classification_loss + regression_loss\n",
    "    return total_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfed0d29",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (800000, 3)\n",
      "Labels shape: (800000, 4)\n",
      "Batch features: [[ 2.90766097e+00 -1.86127695e+00 -2.21639419e+00]\n",
      " [-9.75572381e-01 -1.97358681e+00 -2.26863343e+00]\n",
      " [ 2.55696731e-01 -3.84541787e+00  1.15303708e+00]\n",
      " [-4.10110167e+00  1.22863966e-01 -2.52982966e+00]\n",
      " [ 1.96053089e+00  3.84920313e-01 -3.09661768e-01]\n",
      " [-2.06477198e+00  4.79907236e-02  1.12691745e+00]\n",
      " [ 4.65985163e+00  1.13365274e+00 -8.58173835e-01]\n",
      " [ 3.99686057e+00 -2.68488262e+00  2.12730676e-01]\n",
      " [-2.20684149e+00  9.83906251e-01  5.60129427e-02]\n",
      " [ 1.89142096e-02 -7.75614940e-01 -1.30220741e+00]\n",
      " [ 1.10811381e+00 -2.68825185e-02  2.01498461e+00]\n",
      " [ 2.67087845e+00  3.84920313e-01  2.11946310e+00]\n",
      " [-3.95903215e+00  1.13365274e+00  1.46647254e+00]\n",
      " [-1.97005897e+00  1.80751191e+00  9.17960476e-01]\n",
      " [-4.07294329e-01  3.10047071e-01  3.77369828e-03]\n",
      " [-1.78063295e+00  1.50801895e+00  1.36199405e+00]\n",
      " [-1.02292889e+00 -2.68488262e+00 -1.90295872e+00]\n",
      " [-2.39626751e+00  9.09033009e-01 -1.79848023e+00]\n",
      " [-3.05925857e+00 -1.22485439e+00 -1.22384855e+00]\n",
      " [-3.05925857e+00 -5.88431835e-01  1.15303708e+00]\n",
      " [ 3.50409740e-01 -1.03767129e+00  9.96319342e-01]\n",
      " [ 4.45122749e-01  4.97230177e-01 -1.27608779e+00]\n",
      " [-1.59120694e+00  3.84920313e-01 -1.38056628e+00]\n",
      " [-8.80859372e-01 -7.00741698e-01 -5.44738368e-01]\n",
      " [-3.62753662e+00  2.85573730e+00 -6.49216857e-01]\n",
      " [-3.29604109e+00 -2.04846006e+00 -1.51116439e+00]\n",
      " [ 3.50409740e-01 -1.33716426e+00 -1.56340363e+00]\n",
      " [-4.14845817e+00  1.24596260e+00 -1.43280552e+00]\n",
      " [-3.05925857e+00  1.91982178e+00 -5.44738368e-01]\n",
      " [ 4.23364309e+00 -2.94693896e+00 -1.00704791e-01]\n",
      " [ 8.71331287e-01 -1.44947412e+00 -1.09325043e+00]\n",
      " [-4.00638866e+00 -1.48691074e+00 -1.35444666e+00]]\n",
      "Batch labels: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 19:12:50.080382: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Verify the shapes of features and labels\n",
    "print(\"Features shape:\", features.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "# Configure training and test data for batching and shuffling\n",
    "batch_size = 32\n",
    "train_data = train_data.batch(batch_size).shuffle(1000)\n",
    "test_data = test_data.batch(batch_size)\n",
    "\n",
    "# Display one batch to confirm\n",
    "for batch_features, batch_labels in train_data.take(1):\n",
    "    print(\"Batch features:\", batch_features.numpy())\n",
    "    print(\"Batch labels:\", batch_labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6cfa63",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling3d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6144</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling3d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,573,120</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,672</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">74,016</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m66,048\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3d (\u001b[38;5;33mConv3D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,   │      \u001b[38;5;34m2,688\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling3d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ conv3d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling3D\u001b[0m)      │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6144\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling3d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │  \u001b[38;5;34m1,573,120\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        │     \u001b[38;5;34m24,672\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)       │     \u001b[38;5;34m74,016\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,741,056</span> (6.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,741,056\u001b[0m (6.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,741,056</span> (6.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,741,056\u001b[0m (6.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the model architecture\n",
    "input_layer = layers.Input(shape=(3,))\n",
    "\n",
    "# Dense layers to increase dimensionality\n",
    "x = layers.Dense(128, activation='relu')(input_layer)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Reshape layer for 3D convolution\n",
    "x = layers.Reshape((8, 8, 8, 1))(x)\n",
    "\n",
    "# 3D convolutional layer to capture spatial dependencies\n",
    "x = layers.Conv3D(96, kernel_size=(3, 3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Dense layer for further feature processing\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.3)(x)  # Regularization\n",
    "\n",
    "# Output layers with separate activations\n",
    "classification_output = layers.Dense(96, activation='softmax')(x)    # Classification part with softmax\n",
    "regression_output = layers.Dense(288, activation=None)(x)            # Regression part with linear activation\n",
    "\n",
    "# Concatenate both outputs to form the final output\n",
    "output = layers.Concatenate()([classification_output, regression_output])\n",
    "\n",
    "# Create the model\n",
    "model = models.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "# Compile the model with the custom loss function\n",
    "model.compile(optimizer='adam', loss=custom_loss, metrics=['mae'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af07f42",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 17ms/step - loss: 4.2703 - mae: 0.4717 - val_loss: 3.7993 - val_mae: 0.5062\n",
      "Epoch 2/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 18ms/step - loss: 3.8502 - mae: 0.5242 - val_loss: 3.7441 - val_mae: 0.4803\n",
      "Epoch 3/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 19ms/step - loss: 3.8051 - mae: 0.5075 - val_loss: 3.7244 - val_mae: 0.4692\n",
      "Epoch 4/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 19ms/step - loss: 3.7805 - mae: 0.4957 - val_loss: 3.7134 - val_mae: 0.4540\n",
      "Epoch 5/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 17ms/step - loss: 3.7696 - mae: 0.4882 - val_loss: 3.7047 - val_mae: 0.4578\n",
      "Epoch 6/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 12ms/step - loss: 3.7615 - mae: 0.4801 - val_loss: 3.7023 - val_mae: 0.4518\n",
      "Epoch 7/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 12ms/step - loss: 3.7523 - mae: 0.4756 - val_loss: 3.6908 - val_mae: 0.4466\n",
      "Epoch 8/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 12ms/step - loss: 3.7473 - mae: 0.4716 - val_loss: 3.6903 - val_mae: 0.4426\n",
      "Epoch 9/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 12ms/step - loss: 3.7422 - mae: 0.4696 - val_loss: 3.6841 - val_mae: 0.4423\n",
      "Epoch 10/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 12ms/step - loss: 3.7382 - mae: 0.4677 - val_loss: 3.6987 - val_mae: 0.4483\n",
      "Epoch 11/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7355 - mae: 0.4655 - val_loss: 3.6933 - val_mae: 0.4426\n",
      "Epoch 12/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7309 - mae: 0.4606 - val_loss: 3.6875 - val_mae: 0.4342\n",
      "Epoch 13/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7303 - mae: 0.4564 - val_loss: 3.6855 - val_mae: 0.4376\n",
      "Epoch 14/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7283 - mae: 0.4561 - val_loss: 3.6822 - val_mae: 0.4318\n",
      "Epoch 15/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7271 - mae: 0.4523 - val_loss: 3.6750 - val_mae: 0.4350\n",
      "Epoch 16/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7255 - mae: 0.4502 - val_loss: 3.6944 - val_mae: 0.4253\n",
      "Epoch 17/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7240 - mae: 0.4473 - val_loss: 3.6809 - val_mae: 0.4279\n",
      "Epoch 18/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7219 - mae: 0.4495 - val_loss: 3.6888 - val_mae: 0.4307\n",
      "Epoch 19/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7223 - mae: 0.4506 - val_loss: 3.6898 - val_mae: 0.4290\n",
      "Epoch 20/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7194 - mae: 0.4476 - val_loss: 3.6777 - val_mae: 0.4336\n",
      "Epoch 21/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7193 - mae: 0.4455 - val_loss: 3.6893 - val_mae: 0.4300\n",
      "Epoch 22/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 12ms/step - loss: 3.7188 - mae: 0.4445 - val_loss: 3.6818 - val_mae: 0.4250\n",
      "Epoch 23/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7174 - mae: 0.4441 - val_loss: 3.6872 - val_mae: 0.4243\n",
      "Epoch 24/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7167 - mae: 0.4452 - val_loss: 3.6828 - val_mae: 0.4248\n",
      "Epoch 25/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7158 - mae: 0.4462 - val_loss: 3.6757 - val_mae: 0.4294\n",
      "Epoch 26/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7157 - mae: 0.4470 - val_loss: 3.6767 - val_mae: 0.4310\n",
      "Epoch 27/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 12ms/step - loss: 3.7156 - mae: 0.4458 - val_loss: 3.6923 - val_mae: 0.4275\n",
      "Epoch 28/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7140 - mae: 0.4462 - val_loss: 3.6826 - val_mae: 0.4345\n",
      "Epoch 29/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7116 - mae: 0.4486 - val_loss: 3.6810 - val_mae: 0.4328\n",
      "Epoch 30/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7103 - mae: 0.4490 - val_loss: 3.6848 - val_mae: 0.4326\n",
      "Epoch 31/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7098 - mae: 0.4498 - val_loss: 3.6768 - val_mae: 0.4324\n",
      "Epoch 32/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7102 - mae: 0.4480 - val_loss: 3.6720 - val_mae: 0.4317\n",
      "Epoch 33/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7096 - mae: 0.4470 - val_loss: 3.6785 - val_mae: 0.4296\n",
      "Epoch 34/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7073 - mae: 0.4460 - val_loss: 3.6852 - val_mae: 0.4256\n",
      "Epoch 35/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7076 - mae: 0.4469 - val_loss: 3.6804 - val_mae: 0.4269\n",
      "Epoch 36/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7083 - mae: 0.4460 - val_loss: 3.6758 - val_mae: 0.4334\n",
      "Epoch 37/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7102 - mae: 0.4474 - val_loss: 3.6745 - val_mae: 0.4253\n",
      "Epoch 38/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7080 - mae: 0.4464 - val_loss: 3.6665 - val_mae: 0.4316\n",
      "Epoch 39/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 12ms/step - loss: 3.7065 - mae: 0.4476 - val_loss: 3.6688 - val_mae: 0.4377\n",
      "Epoch 40/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 12ms/step - loss: 3.7067 - mae: 0.4494 - val_loss: 3.6707 - val_mae: 0.4314\n",
      "Epoch 41/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7063 - mae: 0.4503 - val_loss: 3.6780 - val_mae: 0.4345\n",
      "Epoch 42/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 12ms/step - loss: 3.7064 - mae: 0.4488 - val_loss: 3.6693 - val_mae: 0.4339\n",
      "Epoch 43/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 12ms/step - loss: 3.7053 - mae: 0.4469 - val_loss: 3.6808 - val_mae: 0.4305\n",
      "Epoch 44/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7054 - mae: 0.4429 - val_loss: 3.6762 - val_mae: 0.4301\n",
      "Epoch 45/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 12ms/step - loss: 3.7066 - mae: 0.4474 - val_loss: 3.6736 - val_mae: 0.4407\n",
      "Epoch 46/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 12ms/step - loss: 3.7050 - mae: 0.4501 - val_loss: 3.6769 - val_mae: 0.4328\n",
      "Epoch 47/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7047 - mae: 0.4497 - val_loss: 3.6737 - val_mae: 0.4338\n",
      "Epoch 48/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7034 - mae: 0.4492 - val_loss: 3.6621 - val_mae: 0.4337\n",
      "Epoch 49/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7031 - mae: 0.4506 - val_loss: 3.6686 - val_mae: 0.4394\n",
      "Epoch 50/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7035 - mae: 0.4505 - val_loss: 3.6817 - val_mae: 0.4398\n",
      "Epoch 51/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7047 - mae: 0.4509 - val_loss: 3.6650 - val_mae: 0.4344\n",
      "Epoch 52/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 12ms/step - loss: 3.7032 - mae: 0.4500 - val_loss: 3.6745 - val_mae: 0.4388\n",
      "Epoch 53/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7028 - mae: 0.4510 - val_loss: 3.6707 - val_mae: 0.4378\n",
      "Epoch 54/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7029 - mae: 0.4527 - val_loss: 3.6766 - val_mae: 0.4320\n",
      "Epoch 55/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7025 - mae: 0.4511 - val_loss: 3.6800 - val_mae: 0.4384\n",
      "Epoch 56/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7023 - mae: 0.4524 - val_loss: 3.6733 - val_mae: 0.4351\n",
      "Epoch 57/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 12ms/step - loss: 3.7012 - mae: 0.4539 - val_loss: 3.6670 - val_mae: 0.4467\n",
      "Epoch 58/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7011 - mae: 0.4549 - val_loss: 3.6746 - val_mae: 0.4363\n",
      "Epoch 59/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - loss: 3.7025 - mae: 0.4528 - val_loss: 3.6711 - val_mae: 0.4432\n",
      "Epoch 60/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 12ms/step - loss: 3.7019 - mae: 0.4539 - val_loss: 3.6696 - val_mae: 0.4333\n",
      "Epoch 61/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 12ms/step - loss: 3.7017 - mae: 0.4498 - val_loss: 3.6635 - val_mae: 0.4293\n",
      "Epoch 62/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 12ms/step - loss: 3.7013 - mae: 0.4481 - val_loss: 3.6714 - val_mae: 0.4410\n",
      "Epoch 63/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 12ms/step - loss: 3.7016 - mae: 0.4502 - val_loss: 3.6653 - val_mae: 0.4364\n",
      "Epoch 64/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 12ms/step - loss: 3.7007 - mae: 0.4521 - val_loss: 3.6732 - val_mae: 0.4359\n",
      "Epoch 65/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 12ms/step - loss: 3.7001 - mae: 0.4522 - val_loss: 3.6633 - val_mae: 0.4315\n",
      "Epoch 66/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 12ms/step - loss: 3.7012 - mae: 0.4510 - val_loss: 3.6642 - val_mae: 0.4422\n",
      "Epoch 67/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 12ms/step - loss: 3.6989 - mae: 0.4524 - val_loss: 3.6648 - val_mae: 0.4343\n",
      "Epoch 68/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 12ms/step - loss: 3.7003 - mae: 0.4516 - val_loss: 3.6651 - val_mae: 0.4344\n",
      "Epoch 69/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 12ms/step - loss: 3.7000 - mae: 0.4488 - val_loss: 3.6637 - val_mae: 0.4336\n",
      "Epoch 70/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 12ms/step - loss: 3.6987 - mae: 0.4508 - val_loss: 3.6677 - val_mae: 0.4359\n",
      "Epoch 71/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 12ms/step - loss: 3.6994 - mae: 0.4515 - val_loss: 3.6755 - val_mae: 0.4416\n",
      "Epoch 72/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 12ms/step - loss: 3.6980 - mae: 0.4527 - val_loss: 3.6770 - val_mae: 0.4386\n",
      "Epoch 73/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 12ms/step - loss: 3.6990 - mae: 0.4522 - val_loss: 3.6627 - val_mae: 0.4429\n",
      "Epoch 74/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 12ms/step - loss: 3.6994 - mae: 0.4524 - val_loss: 3.6639 - val_mae: 0.4415\n",
      "Epoch 75/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 12ms/step - loss: 3.6978 - mae: 0.4520 - val_loss: 3.6633 - val_mae: 0.4315\n",
      "Epoch 76/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 12ms/step - loss: 3.6990 - mae: 0.4528 - val_loss: 3.6710 - val_mae: 0.4500\n",
      "Epoch 77/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 12ms/step - loss: 3.6988 - mae: 0.4537 - val_loss: 3.6682 - val_mae: 0.4371\n",
      "Epoch 78/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 12ms/step - loss: 3.6989 - mae: 0.4527 - val_loss: 3.6581 - val_mae: 0.4473\n",
      "Epoch 79/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 12ms/step - loss: 3.6954 - mae: 0.4547 - val_loss: 3.6665 - val_mae: 0.4435\n",
      "Epoch 80/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 12ms/step - loss: 3.6970 - mae: 0.4537 - val_loss: 3.6696 - val_mae: 0.4423\n",
      "Epoch 81/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 12ms/step - loss: 3.6979 - mae: 0.4548 - val_loss: 3.6612 - val_mae: 0.4431\n",
      "Epoch 82/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 12ms/step - loss: 3.6972 - mae: 0.4550 - val_loss: 3.6691 - val_mae: 0.4404\n",
      "Epoch 83/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 12ms/step - loss: 3.6975 - mae: 0.4542 - val_loss: 3.6642 - val_mae: 0.4381\n",
      "Epoch 84/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 12ms/step - loss: 3.6962 - mae: 0.4531 - val_loss: 3.6669 - val_mae: 0.4411\n",
      "Epoch 85/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 12ms/step - loss: 3.6979 - mae: 0.4532 - val_loss: 3.6813 - val_mae: 0.4426\n",
      "Epoch 86/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 12ms/step - loss: 3.6984 - mae: 0.4543 - val_loss: 3.6602 - val_mae: 0.4397\n",
      "Epoch 87/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 12ms/step - loss: 3.6968 - mae: 0.4525 - val_loss: 3.6643 - val_mae: 0.4397\n",
      "Epoch 88/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 12ms/step - loss: 3.6972 - mae: 0.4527 - val_loss: 3.6684 - val_mae: 0.4435\n",
      "Epoch 89/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 12ms/step - loss: 3.6977 - mae: 0.4519 - val_loss: 3.6686 - val_mae: 0.4408\n",
      "Epoch 90/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 12ms/step - loss: 3.6969 - mae: 0.4537 - val_loss: 3.6660 - val_mae: 0.4422\n",
      "Epoch 91/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 12ms/step - loss: 3.6951 - mae: 0.4577 - val_loss: 3.6614 - val_mae: 0.4458\n",
      "Epoch 92/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 12ms/step - loss: 3.6957 - mae: 0.4499 - val_loss: 3.6629 - val_mae: 0.4378\n",
      "Epoch 93/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 12ms/step - loss: 3.6968 - mae: 0.4511 - val_loss: 3.6722 - val_mae: 0.4451\n",
      "Epoch 94/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 12ms/step - loss: 3.6972 - mae: 0.4527 - val_loss: 3.6677 - val_mae: 0.4342\n",
      "Epoch 95/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 12ms/step - loss: 3.6974 - mae: 0.4523 - val_loss: 3.6700 - val_mae: 0.4461\n",
      "Epoch 96/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 12ms/step - loss: 3.6958 - mae: 0.4538 - val_loss: 3.6679 - val_mae: 0.4444\n",
      "Epoch 97/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 12ms/step - loss: 3.6963 - mae: 0.4515 - val_loss: 3.6653 - val_mae: 0.4442\n",
      "Epoch 98/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 12ms/step - loss: 3.6941 - mae: 0.4527 - val_loss: 3.6711 - val_mae: 0.4355\n",
      "Epoch 99/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 12ms/step - loss: 3.6968 - mae: 0.4554 - val_loss: 3.6622 - val_mae: 0.4431\n",
      "Epoch 100/100\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 12ms/step - loss: 3.6938 - mae: 0.4523 - val_loss: 3.6680 - val_mae: 0.4394\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set training parameters\n",
    "epochs = 100\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data, \n",
    "                    validation_data=test_data, \n",
    "                    epochs=epochs,\n",
    "                    callbacks=[tensorboard_callback])\n",
    "\n",
    "# Optional: Plotting training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot loss and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03ac36e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Sample Comparisons (Predicted vs True):\n",
      "\n",
      "Sample 11:\n",
      "Predicted p_id -> 75 (1.00e+00), 71 (8.59e-09), 79 (1.36e-12), 55 (6.39e-15)\n",
      "True p_id      -> 75\n",
      "Predicted (xi1, xi2) -> patch 75: (0.58, 0.70), patch 71: (0.48, 0.93)\n",
      "True (xi1, xi2)      -> (0.63, 0.75)\n",
      "Predicted gn      -> patch 75: -0.384, patch 71: -0.388\n",
      "True gn           -> -0.344\n",
      "------------------------------\n",
      "Sample 29:\n",
      "Predicted p_id -> 4 (1.00e+00), 81 (6.72e-07), 67 (1.77e-15), 40 (4.95e-16)\n",
      "True p_id      -> 4\n",
      "Predicted (xi1, xi2) -> patch 4: (0.76, 0.07), patch 81: (0.18, 0.83)\n",
      "True (xi1, xi2)      -> (0.87, 0.09)\n",
      "Predicted gn      -> patch 4: -0.419, patch 81: -0.666\n",
      "True gn           -> -0.508\n",
      "------------------------------\n",
      "Sample 28:\n",
      "Predicted p_id -> 80 (1.00e+00), 16 (3.28e-14), 20 (1.01e-17), 28 (5.57e-23)\n",
      "True p_id      -> 80\n",
      "Predicted (xi1, xi2) -> patch 80: (0.84, 0.60), patch 16: (0.50, 0.36)\n",
      "True (xi1, xi2)      -> (0.74, 0.61)\n",
      "Predicted gn      -> patch 80: 1.160, patch 16: 1.151\n",
      "True gn           -> 1.133\n",
      "------------------------------\n",
      "Sample 6:\n",
      "Predicted p_id -> 84 (1.00e+00), 59 (5.00e-12), 88 (9.84e-16), 8 (1.64e-16)\n",
      "True p_id      -> 84\n",
      "Predicted (xi1, xi2) -> patch 84: (0.18, 0.32), patch 59: (0.61, 0.60)\n",
      "True (xi1, xi2)      -> (0.09, 0.37)\n",
      "Predicted gn      -> patch 84: 0.053, patch 59: 0.297\n",
      "True gn           -> -0.025\n",
      "------------------------------\n",
      "Sample 4:\n",
      "Predicted p_id -> 91 (1.00e+00), 31 (3.56e-15), 95 (6.75e-16), 87 (4.22e-17)\n",
      "True p_id      -> 91\n",
      "Predicted (xi1, xi2) -> patch 91: (0.95, 0.83), patch 31: (0.08, 0.45)\n",
      "True (xi1, xi2)      -> (0.92, 0.91)\n",
      "Predicted gn      -> patch 91: -0.419, patch 31: 0.348\n",
      "True gn           -> -0.334\n",
      "------------------------------\n",
      "Sample 1:\n",
      "Predicted p_id -> 60 (1.00e+00), 67 (4.33e-14), 38 (1.59e-14), 19 (1.09e-14)\n",
      "True p_id      -> 60\n",
      "Predicted (xi1, xi2) -> patch 60: (0.47, 0.57), patch 67: (0.15, 0.94)\n",
      "True (xi1, xi2)      -> (0.50, 0.61)\n",
      "Predicted gn      -> patch 60: 0.263, patch 67: 0.429\n",
      "True gn           -> 0.264\n",
      "------------------------------\n",
      "Sample 24:\n",
      "Predicted p_id -> 62 (1.00e+00), 58 (9.84e-20), 63 (9.11e-20), 48 (3.33e-20)\n",
      "True p_id      -> 62\n",
      "Predicted (xi1, xi2) -> patch 62: (0.18, 0.09), patch 58: (0.73, -0.11)\n",
      "True (xi1, xi2)      -> (0.18, 0.07)\n",
      "Predicted gn      -> patch 62: 0.949, patch 58: 0.767\n",
      "True gn           -> 0.982\n",
      "------------------------------\n",
      "Sample 3:\n",
      "Predicted p_id -> 82 (1.00e+00), 81 (3.34e-05), 8 (1.74e-11), 86 (5.77e-13)\n",
      "True p_id      -> 82\n",
      "Predicted (xi1, xi2) -> patch 82: (0.89, 0.28), patch 81: (0.10, 0.34)\n",
      "True (xi1, xi2)      -> (0.97, 0.04)\n",
      "Predicted gn      -> patch 82: 0.412, patch 81: 0.322\n",
      "True gn           -> 0.298\n",
      "------------------------------\n",
      "Sample 19:\n",
      "Predicted p_id -> 2 (1.00e+00), 55 (9.30e-14), 39 (2.54e-16), 1 (8.24e-17)\n",
      "True p_id      -> 2\n",
      "Predicted (xi1, xi2) -> patch 2: (0.36, 0.79), patch 55: (0.46, 0.52)\n",
      "True (xi1, xi2)      -> (0.47, 0.78)\n",
      "Predicted gn      -> patch 2: 1.104, patch 55: 0.217\n",
      "True gn           -> 1.051\n",
      "------------------------------\n",
      "Sample 22:\n",
      "Predicted p_id -> 93 (1.00e+00), 52 (2.64e-07), 94 (1.95e-11), 60 (5.56e-12)\n",
      "True p_id      -> 93\n",
      "Predicted (xi1, xi2) -> patch 93: (0.18, 0.55), patch 52: (0.72, 0.38)\n",
      "True (xi1, xi2)      -> (0.18, 0.51)\n",
      "Predicted gn      -> patch 93: -0.380, patch 52: -0.386\n",
      "True gn           -> -0.461\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 09:43:32.213263: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of samples to display for comparison\n",
    "num_samples = 10\n",
    "\n",
    "# Take a batch from the test set\n",
    "for test_features, test_labels in test_data.take(1):\n",
    "    # Make predictions on the batch\n",
    "    predictions = model.predict(test_features)\n",
    "\n",
    "    # Randomly select a few samples for comparison\n",
    "    indices = np.random.choice(range(len(test_features)), num_samples, replace=False)\n",
    "    print(\"Sample Comparisons (Predicted vs True):\\n\")\n",
    "    \n",
    "    for i in indices:\n",
    "        pred = predictions[i]\n",
    "        true = test_labels[i].numpy()\n",
    "        \n",
    "        # Classification predictions (first 96 elements)\n",
    "        pred_p_id = pred[:96]\n",
    "        true_p_id_index = np.argmax(true[:96])  # True p_id index\n",
    "\n",
    "        # Sort predictions to find the top 4 likely patches\n",
    "        top4_indices = np.argsort(pred_p_id)[-4:][::-1]\n",
    "        top4_values = pred_p_id[top4_indices]\n",
    "\n",
    "        # Display predicted and true `p_id`\n",
    "        print(f\"Sample {i + 1}:\")\n",
    "        print(\"Predicted p_id ->\", ', '.join([f\"{idx} ({val:.2e})\" for idx, val in zip(top4_indices, top4_values)]))\n",
    "        print(f\"True p_id      -> {true_p_id_index}\")\n",
    "\n",
    "        # Surface coordinates and gn predictions for the top 2 patches\n",
    "        print(\"Predicted (xi1, xi2) ->\", ', '.join([f\"patch {idx}: ({pred[96 + idx]:.2f}, {pred[192 + idx]:.2f})\" for idx in top4_indices[:2]]))\n",
    "        print(f\"True (xi1, xi2)      -> ({true[96 + true_p_id_index]:.2f}, {true[192 + true_p_id_index]:.2f})\")\n",
    "\n",
    "        # gn predictions for the top 2 patches\n",
    "        print(\"Predicted gn      ->\", ', '.join([f\"patch {idx}: {pred[288 + idx]:.3f}\" for idx in top4_indices[:2]]))\n",
    "        print(f\"True gn           -> {true[288 + true_p_id_index]:.3f}\")\n",
    "        print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d4cb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = []\n",
    "for file in glob.glob(csv_files_path):\n",
    "    df = pd.read_csv(file, header=None)  # Load without headers\n",
    "    if df.shape[1] == 7:                 # Ensure it has exactly 7 columns\n",
    "        data_frames.append(df)           # Append if structure is correct\n",
    "    else:\n",
    "        print(f\"Skipping file {file} due to unexpected number of columns: {df.shape[1]}\")\n",
    "\n",
    "# Concatenate all valid DataFrames\n",
    "all_data = pd.concat(data_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee01364",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('sampled_data_1_percent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53052bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(test_features)[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e432c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape\n",
    "all_data = np.array(all_data)\n",
    "print(min(all_data[:,0]),max(all_data[:,0]))\n",
    "print(min(all_data[:,1]),max(all_data[:,1]))\n",
    "print(min(all_data[:,2]),max(all_data[:,2]))\n",
    "print(min(all_data[:,3]),max(all_data[:,3]))\n",
    "print(min(all_data[:,4]),max(all_data[:,4]))\n",
    "print(min(all_data[:,5]),max(all_data[:,5]))\n",
    "print(min(all_data[:,6]),max(all_data[:,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25281931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in the .keras format\n",
    "model_name = 'CLASSIF_REGRESS_128_512_CONV3D_256_20EPOCHS'\n",
    "\n",
    "model.save(model_name+'.keras')\n",
    "\n",
    "import json\n",
    "\n",
    "# Save the training history\n",
    "with open(model_name+'.json', 'w') as f:\n",
    "    json.dump(history.history, f)\n",
    "\n",
    "\n",
    "# To later load doing:\n",
    "# from tensorflow.keras.models import load_model\n",
    "# model = load_model('my_model.keras')\n",
    "\n",
    "# with open('training_history.json', 'r') as f:\n",
    "#     history_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe6a72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
